1*2
rm(list = ls())
filename <- "kmeans_insurance_data_evaluation.txt"
time1 <- Sys.time()
library(clustMixType)
install.packages(clustMixType)
library('clustMixType')
---
title: "R Notebook"
output: html_notebook
---
library(dplyr)
library(Dplyr)
library('Dplyr')
library("Dplyr")
library("plyr")
library("dplyr")
install.packages('dplyr')
install.packages(c('ggplot2','swirl','readxl'))
rm(list = ls())
filename <- "kmeans_insurance_data_evaluation.txt"
time1 <- Sys.time()
library(clustMixType)
install.packages('clustMixType')
rm(list = ls())
filename <- "kmeans_insurance_data_evaluation.txt"
time1 <- Sys.time()
library(clustMixType)
#setwd("Dropbox/sharedFolders/Marius_Arbeit/190510_Daten_Versicherungen/")
datafilename <- "190423_DISP_TAB_10000'.csv"
x <- read.csv("190423_DISP_TAB_10000.csv")
rm(list = ls())
filename <- "kmeans_insurance_data_evaluation.txt"
time1 <- Sys.time()
library(clustMixType)
#setwd("Dropbox/sharedFolders/Marius_Arbeit/190510_Daten_Versicherungen/")
datafilename <- "190423_DISP_TAB_10000'.csv"
x <- read.csv("190423_DISP_TAB_10000.csv")
rm(list = ls())
filename <- "kmeans_insurance_data_evaluation.txt"
time1 <- Sys.time()
library(clustMixType)
#setwd("Dropbox/sharedFolders/Marius_Arbeit/190510_Daten_Versicherungen/")
datafilename <- "190423_DISP_TAB_10000'.csv"
x <- read.csv("190423_DISP_TAB_10000.csv")
x_orig <- x
#Exclude following values:
x$VNR     <- NULL
x$KNR_VN1 <- NULL
x$KNR_VN2 <- NULL
x$KNR_VP1 <- NULL
x$KNR_VP2 <- NULL
#delete empty columns (or only one entry)
for (i in length(x):1){
if (length(unique(x[,i]))==1) {
x <- x[,-i]
}
}
#how many different values per element
y <- array(1:length(x))
for (i in length(x):1){
y[i] <- length(unique(x[,i]))
}
class_of_x <- sapply(x,class)
#summary(sapply(sapply(x,class),as.factor))
#which(class_of_x %in% "integer")
x[is.na(x)] <- 0
class_index_int <- which(class_of_x == "integer")
x[,class_index_int] <- lapply(x[,class_index_int],as.factor)
#use date as date
data <- x
date_vec <- sapply(data, function(x) !all(is.na(as.Date(as.character(x),format="%d/%m/%Y"))))
date_vec <- which(date_vec,TRUE)
for (i in date_vec) {
x[,i] <- as.Date(x[,i],format ="%d/%m/%Y")
}
x[is.na(x)] <- "1900-01-01"
for (i in date_vec) {
x[,i]<- as.numeric(x[,i])
}
num_vec <- which(sapply(x,class) %in% "numeric")
x[,num_vec] <- apply(x[,num_vec],MARGIN = 2, FUN = function(X) (X-min(X))/diff(range(X)))
prep_time <- difftime(Sys.time(),time1, units = "mins")
infos <- cat("\n\n",as.character(Sys.time()), datafilename, " #Numerical Predictors:", length(num_vec), " #Logical Predictors:", length(x)-length(num_vec), " Datasize:", dim(x), " preptime",prep_time, file = filename,append = TRUE)
write.table(infos, file = filename, append = TRUE,row.names = FALSE,col.names = FALSE)
for (k in c(4)){ #,16,20,24)) {
set.seed(42)
time1 <- Sys.time()
ob <- kproto(x,k,iter.max = 15, nstart = 6)
#time2 <- Sys.time() - time1
time_diff <- difftime(Sys.time(),time1, units = "mins")
infos <- cat("\n#Clusters:", k,"\tLambda:", ob$lambda, "\ttot.withinss:",
ob$tot.withinss,"\tclustersize: ",sort(t(ob$size)), "\t#iter: ",ob$iter,"\ttime: ", time_diff, file = filename,append = TRUE)
write.table(infos, file = filename, append = TRUE,row.names = FALSE,col.names = FALSE)
} # end k for loop
ob$size #spannend
ob$iter #spannend
ob$centers #nicht so
ob$tot.withinss
ob$withinss #ggf
ob$lambda
ob$trace$moved
#clprofiles(ob,x)
barplot(sort(ob$size,decreasing = TRUE))
prep_time
#infos <- cat("\nLambda:", ob$lambda, "  tot.withinss:",
#        ob$tot.withinss,"\n size:     ", file = filename,append = TRUE)
#    write.table(infos,sep = "\t", file = filename, append = TRUE,row.names = FALSE, col.names = FALSE)
#    write.table(t(ob$size), file = filename, append = TRUE,row.names = FALSE,col.names = FALSE)
install.packages('Rfast')
library(Rfast)
library('Rfast')
rm(list = ls())
filename <- "kmeans_insurance_data_evaluation.txt"
time1 <- Sys.time()
library(clustMixType)
#setwd("Dropbox/sharedFolders/Marius_Arbeit/190510_Daten_Versicherungen/")
datafilename <- "190423_DISP_TAB_10000'.csv"
x <- read.csv("190423_DISP_TAB_10000.csv")
x_orig <- x
#Exclude following values:
x$VNR     <- NULL
x$KNR_VN1 <- NULL
x$KNR_VN2 <- NULL
x$KNR_VP1 <- NULL
x$KNR_VP2 <- NULL
#delete empty columns (or only one entry)
for (i in length(x):1){
if (length(unique(x[,i]))==1) {
x <- x[,-i]
}
}
#how many different values per element
y <- array(1:length(x))
for (i in length(x):1){
y[i] <- length(unique(x[,i]))
}
class_of_x <- sapply(x,class)
#summary(sapply(sapply(x,class),as.factor))
#which(class_of_x %in% "integer")
x[is.na(x)] <- 0
class_index_int <- which(class_of_x == "integer")
x[,class_index_int] <- lapply(x[,class_index_int],as.factor)
#use date as date
data <- x
date_vec <- sapply(data, function(x) !all(is.na(as.Date(as.character(x),format="%d/%m/%Y"))))
date_vec <- which(date_vec,TRUE)
for (i in date_vec) {
x[,i] <- as.Date(x[,i],format ="%d/%m/%Y")
}
x[is.na(x)] <- "1900-01-01"
for (i in date_vec) {
x[,i]<- as.numeric(x[,i])
}
num_vec <- which(sapply(x,class) %in% "numeric")
x[,num_vec] <- apply(x[,num_vec],MARGIN = 2, FUN = function(X) (X-min(X))/diff(range(X)))
prep_time <- difftime(Sys.time(),time1, units = "mins")
infos <- cat("\n\n",as.character(Sys.time()), datafilename, " #Numerical Predictors:", length(num_vec), " #Logical Predictors:", length(x)-length(num_vec), " Datasize:", dim(x), " preptime",prep_time, file = filename,append = TRUE)
write.table(infos, file = filename, append = TRUE,row.names = FALSE,col.names = FALSE)
for (k in c(4)){ #,16,20,24)) {
set.seed(42)
time1 <- Sys.time()
ob <- kproto(x,k,iter.max = 15, nstart = 6)
#time2 <- Sys.time() -ins time1
time_diff <- difftime(Sys.time(),time1, units = "mins")
infos <- cat("\n#Clusters:", k,"\tLambda:", ob$lambda, "\ttot.withinss:",
ob$tot.withinss,"\tclustersize: ",sort(t(ob$size)), "\t#iter: ",ob$iter,"\ttime: ", time_diff, file = filename,append = TRUE)
write.table(infos, file = filename, append = TRUE,row.names = FALSE,col.names = FALSE)
} # end k for loop
ob$size #spannend
ob$iter #spannend
ob$centers #nicht so
ob$tot.withinss
ob$withinss #ggf
ob$lambda
ob$trace$moved
#clprofiles(ob,x)
barplot(sort(ob$size,decreasing = TRUE))
prep_time
#infos <- cat("\nLambda:", ob$lambda, "  tot.withinss:",
#        ob$tot.withinss,"\n size:     ", file = filename,append = TRUE)
#    write.table(infos,sep = "\t", file = filename, append = TRUE,row.names = FALSE, col.names = FALSE)
#    write.table(t(ob$size), file = filename, append = TRUE,row.names = FALSE,col.names = FALSE)
ob$dists
colMins(ob$dists)
rowMins(ob$dists)
ob$centers
rowMins(ob$dists, vlaue = TRUE)
rowMins(ob$dists, value = TRUE)
mean(rowMins(ob$dists, vlaue = TRUE))
mean(rowMins(ob$dists, value = TRUE))
rowMins(ob$dists, value = TRUE) - mean(rowMins(ob$dists, value = TRUE))
rowMins(ob$dists, value = TRUE) / mean(rowMins(ob$dists, value = TRUE))
max(rowMins(ob$dists, value = TRUE) / mean(rowMins(ob$dists, value = TRUE)))
sd(rowMins(ob$dists, value = TRUE)))
sd(rowMins(ob$dists, value = TRUE))
rowMins(ob$dists, value = TRUE) >= sd(rowMins(ob$dists, value = TRUE)) + mean(rowMins(ob$dists, value = TRUE))
tf=rowMins(ob$dists, value = TRUE) >= sd(rowMins(ob$dists, value = TRUE)) + mean(rowMins(ob$dists, value = TRUE))
tf
count.fields(tf)
count_value(tf, TRUE)
tf=rowMins(ob$dists, value = TRUE) >= 2*sd(rowMins(ob$dists, value = TRUE)) + mean(rowMins(ob$dists, value = TRUE))
tf
rowMins(ob$dists, value = TRUE) * tf
rowMins(ob$dists) * tf
tf=rowMins(ob$dists, value = TRUE) >= 2*sd(rowMins(ob$dists, value = TRUE)) + mean(rowMins(ob$dists, value = TRUE))
tf
sum(tf, na.rm = TRUE)
ob$dists
ob$withinss
ob$tot.withinss
ob$tot.withinss/4
ob$size
ob$tot.withinss/ob$size
ob$withinss/ob$size
sum(ob$withinss/ob$size)/4
install.packages('markdown','klar','readxl', 'RMarkdown')
install.packages(c('markdown','klar','readxl', 'RMarkdown'))
install.packages(c('markdown','klar','readxl', 'RMarkdown'))
install.packages(c('klaR', 'Rmarkdown'))
install.packages(c('rmarkdown'))
pwd
head(rownames(a),3)
install.packages("slidify")
library(ggplot2)
search()
cor(c(1,2,3),c(2,3,4))
cor(c(1,2,3),c(2,3,0))
source("corr.R")
setwd("C:/Users/vtmw-07/OneDrive - vtmw AG/Schulungen/KI/Data Science (John Hopkins)/Code")
source("corr.R")
cr <- corr("specdata", 150)
head(cr)
summary(cr)
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata", 5000)
summary(cr)
length(cr)
cr <- corr("specdata")
length(cr)
summary(cr)
source("pollutant.R")
source("pollutantmean.R")
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "sulfate", 34)
pollutantmean("specdata", "nitrate")
source("complete.R")
cc <- complete("specdata", c(6, 10, 20, 34, 100, 200, 310))
print(cc$nobs)
cc <- complete("specdata", 54)
print(cc$nobs)
set.seed(42)
cc <- complete("specdata", 332:1)
use <- sample(332, 10)
print(cc[use, "nobs"])
set.seed(42)
cc <- complete("specdata", 332:1)
use <- sample(332, 10)
print(cc[use, "nobs"])
cr <- corr("specdata")
cr <- sort(cr)
set.seed(868)
out <- round(cr[sample(length(cr), 5)], 4)
print(out)
cr <- corr("specdata", 129)
cr <- sort(cr)
n <- length(cr)
set.seed(197)
out <- c(n, round(cr[sample(n, 5)], 4))
print(out)
cr <- corr("specdata", 2000)
n <- length(cr)
cr <- corr("specdata", 1000)
cr <- sort(cr)
print(c(n, round(cr, 4)))
vstr <- "3.5.1
""
vstr <- "3.5.1"
set.seed(42)
cc <- complete("specdata", 332:1)
use <- sample(332, 10)
print(cc[use, "nobs"])
vstr <- "3.5.1"
RNGversion(vstr)
set.seed(42)
cc <- complete("specdata", 332:1)
use <- sample(332, 10)
print(cc[use, "nobs"])
cr <- corr("specdata")
cr <- sort(cr)
set.seed(868)
out <- round(cr[sample(length(cr), 5)], 4)
print(out)
cr <- corr("specdata", 129)
cr <- sort(cr)
n <- length(cr)
set.seed(197)
out <- c(n, round(cr[sample(n, 5)], 4))
print(out)
